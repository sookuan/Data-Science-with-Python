{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PopLE1ywNQsa"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e45O_NedNQsd"
   },
   "source": [
    "# Lab 2.1.1\n",
    "# *Data Wrangling and Munging with Pandas*\n",
    "\n",
    "In this lab we work through reading in files of a range of formats, then manipulating a dataset to handle missing values and performing data profiling.\n",
    "\n",
    "**Note**: It you are new to programming, it is fine if you are not able to complete every exercise. Fewer hints are given here compared with module 1 to train you to become increasingly independent. Reach out to your trainer if any tasks are taking too long and additional support is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qr08YR1PNQsf"
   },
   "source": [
    "## Part 1: Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH9yA6LINQsh"
   },
   "source": [
    "The term \"data wrangling\" is analogous to capturing wild horses and getting them into a fenced area; the horses are data and the fencing is your computer. The more common data wrangling tasks include:\n",
    "\n",
    "- reading flat files\n",
    "- reading Excel files\n",
    "- downloading from web pages\n",
    "  - csv\n",
    "  - html\n",
    "  - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "baKB6_WIBp_8"
   },
   "outputs": [],
   "source": [
    "# Import Numpy and Pandas library\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8G9iecYNQsr"
   },
   "source": [
    "*It is good practice to display the library version numbers for future reference:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MC0XSmScBqAD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy:  1.26.4\n",
      "Pandas:  2.2.3\n"
     ]
    }
   ],
   "source": [
    "# Check the version of Numpy and Pandas\n",
    "print('Numpy: ', np.__version__)\n",
    "print('Pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzTKAG1LNQsx"
   },
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE2wYKPNNQsy"
   },
   "source": [
    "Below are three attempts to load the file \"bikeshare.csv\" (from the DATA folder) into a DataFrame named `bikes`. Why are they wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZV2HMWarNQsz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  instant,dteday,season,yr,mnth,hr,holiday,weekd...\n",
      "1  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...\n",
      "2  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "3  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "4  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...\n",
      "\n",
      "  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,0,3,13,16\n",
      "0  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "1  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "2  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "3  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "4  6,2011-01-01,1,0,1,5,0,6,0,2,0.24,0.2576,0.75,...     \n",
      "\n",
      "  instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "0  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...                                                                   \n",
      "1  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "2  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "3  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n",
      "4  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n"
     ]
    }
   ],
   "source": [
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = None) \n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = 1)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('bikeshare.csv', header = 0)\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSiMJN9NNQs4"
   },
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDFYVoPINQs6"
   },
   "source": [
    "Load the file \"bikeshare.csv\" into a DataFrame named `bikes`, and confirm that it was loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wH2wuPznNQs8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0           1       2   3     4   5        6        7           8   \\\n",
      "0  instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday   \n",
      "1        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "2        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "3        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "4        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "\n",
      "           9     10      11    12         13      14          15   16  \n",
      "0  weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "1           1  0.24  0.2879  0.81          0       3          13   16  \n",
      "2           1  0.22  0.2727   0.8          0       8          32   40  \n",
      "3           1  0.22  0.2727   0.8          0       5          27   32  \n",
      "4           1  0.24  0.2879  0.75          0       3          10   13  \n",
      "\n",
      "   1  2011-01-01  1.1  0  1.2  0.1  0.2  6  0.3  1.3  0.24  0.2879  0.81  \\\n",
      "0  2  2011-01-01    1  0    1    1    0  6    0    1  0.22  0.2727  0.80   \n",
      "1  3  2011-01-01    1  0    1    2    0  6    0    1  0.22  0.2727  0.80   \n",
      "2  4  2011-01-01    1  0    1    3    0  6    0    1  0.24  0.2879  0.75   \n",
      "3  5  2011-01-01    1  0    1    4    0  6    0    1  0.24  0.2879  0.75   \n",
      "4  6  2011-01-01    1  0    1    5    0  6    0    2  0.24  0.2576  0.75   \n",
      "\n",
      "      0.4  3  13  16  \n",
      "0  0.0000  8  32  40  \n",
      "1  0.0000  5  27  32  \n",
      "2  0.0000  3  10  13  \n",
      "3  0.0000  0   1   1  \n",
      "4  0.0896  0   1   1  \n",
      "\n",
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "# Read the CSV file without header\n",
    "bikes = pd.read_csv('bikeshare.csv', header = None) \n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# Read the CSV file with second row as header\n",
    "bikes = pd.read_csv('bikeshare.csv', header = 1)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# Read the CSV file with first row as header\n",
    "bikes = pd.read_csv('bikeshare.csv', header = 0)\n",
    "print(bikes.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEwczD29NQtA"
   },
   "source": [
    "Note that we could have used `read.csv()` above. `read_table()` is necessary when `sep` is not the comma character, or we need fine control that `read.csv()` does not provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPEoeHGGNQtC"
   },
   "source": [
    "Flat files can be full of surprises. Here are some issues to watch out for:\n",
    "\n",
    "- separator character is something other than the comma\n",
    "  - \";\", \"|\", and tab are popular\n",
    "- newline character is something other than what the O/S expects\n",
    "  - Tip: Don't hard-code the character codes for carriage returns, linefeeds, etc. Use Python's built-in representation instead (e.g. Python translates \"\\n\" to the newline character and \"\\t\" to the tab character on any O/S).\n",
    "- truncated lines\n",
    "  - if there are empty fields at the end of a line it is possible that their separators will be missing, resulting in a \"jagged\" file\n",
    "- embedded commas or quotes\n",
    "  - a free-text field containing embedded commas may split into separate fields on input\n",
    "  - a free-text field containing embedded quotes may not parse correctly\n",
    "- unescaped characters\n",
    "  - the \"\\\" character indicates a control code to Python, which will break the I/O\n",
    "    - e.g. the substring \"\\u0123\" will be interpreted as Unicode(0123) -- which may not be what the file creator intended\n",
    "  - these may need to be fixed by loading whole strings and then parsing into a new data frame\n",
    "  \n",
    "Tip: Most issues can be dealt with by correctly specifying the parameters of the function you use to load the file. Read the documentation before reading the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0G5PtA2NQtC"
   },
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Kpf_qSe2xlQA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\users\\nsk_z\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Mj9q0hNYxeU_"
   },
   "outputs": [],
   "source": [
    "# Import the read_excel package\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XDjzKP6nNQtF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species_No</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species_No  Petal_width  Petal_length  Sepal_width  Sepal_length  \\\n",
       "0             1          0.2           1.4          3.5           5.1   \n",
       "1             1          0.2           1.4          3.0           4.9   \n",
       "2             1          0.2           1.3          3.2           4.7   \n",
       "3             1          0.2           1.5          3.1           4.6   \n",
       "4             1          0.2           1.4          3.6           5.0   \n",
       "..          ...          ...           ...          ...           ...   \n",
       "145           3          2.3           5.2          3.0           6.7   \n",
       "146           3          1.9           5.0          2.5           6.3   \n",
       "147           3          2.0           5.2          3.0           6.5   \n",
       "148           3          2.3           5.4          3.4           6.2   \n",
       "149           3          1.8           5.1          3.0           5.9   \n",
       "\n",
       "    Species_name  \n",
       "0         Setosa  \n",
       "1         Setosa  \n",
       "2         Setosa  \n",
       "3         Setosa  \n",
       "4         Setosa  \n",
       "..           ...  \n",
       "145    Verginica  \n",
       "146    Verginica  \n",
       "147    Verginica  \n",
       "148    Verginica  \n",
       "149    Verginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the excel file (Iris.xls)\n",
    "df = pd.read_excel('Iris.xls', sheet_name = 'Data') # file comes from the DATA folder\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjWx-Xo0NQtH"
   },
   "source": [
    "It is usually better to load data correctly than to meddle with the source file or load it 'warts and all' and then try to parse it in code. The Pandas functions for reading files have parameters that provide the control we need. For example, we could make multiple calls to `read_excel()`, using combinations of the `header`, `usecols`, `skiprows`, `nrows`, and `skipfooter` parameters to load one table at a time from a spreadsheet with multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tC5kzTsMNQtI"
   },
   "source": [
    "Load the above file without the unwanted column Species_No:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-P70uSXsNQtI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Petal_width  Petal_length  Sepal_width  Sepal_length Species_name\n",
       "0            0.2           1.4          3.5           5.1       Setosa\n",
       "1            0.2           1.4          3.0           4.9       Setosa\n",
       "2            0.2           1.3          3.2           4.7       Setosa\n",
       "3            0.2           1.5          3.1           4.6       Setosa\n",
       "4            0.2           1.4          3.6           5.0       Setosa\n",
       "..           ...           ...          ...           ...          ...\n",
       "145          2.3           5.2          3.0           6.7    Verginica\n",
       "146          1.9           5.0          2.5           6.3    Verginica\n",
       "147          2.0           5.2          3.0           6.5    Verginica\n",
       "148          2.3           5.4          3.4           6.2    Verginica\n",
       "149          1.8           5.1          3.0           5.9    Verginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Read the excel file and skip the column \"Species_No\"\n",
    "column = ['Petal_width', 'Petal_length', 'Sepal_width', 'Sepal_length','Species_name']\n",
    "df = pd.read_excel('Iris.xls', sheet_name = 'Data', usecols = column ) # file comes from the DATA folder\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTkOz1KsNQtK"
   },
   "source": [
    "### Importing Data Directly from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFHi_S4fNQtK"
   },
   "source": [
    "We usually want to store a local copy of a data file that we download from the Web, but when data retention is not a priority it is convenient to download the data directly into our running Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jS7P3oXQNQtL"
   },
   "source": [
    "#### Importing Text Files from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-hzkxRRNQtL"
   },
   "source": [
    "The web is the 'wild west' of data formats. However, we can usually expect good behaviour from files that are automatically generated by a service, such as the earthquake report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QFuaZ82hNQtM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-31T13:14:52.831Z</td>\n",
       "      <td>-15.8326</td>\n",
       "      <td>-174.2043</td>\n",
       "      <td>108.698</td>\n",
       "      <td>4.7</td>\n",
       "      <td>mb</td>\n",
       "      <td>62</td>\n",
       "      <td>93</td>\n",
       "      <td>3.023</td>\n",
       "      <td>0.88</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-05-31T13:34:35.040Z</td>\n",
       "      <td>45 km WNW of Hihifo, Tonga</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>11.78</td>\n",
       "      <td>7.257</td>\n",
       "      <td>0.055</td>\n",
       "      <td>101</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  latitude  longitude    depth  mag magType  nst  \\\n",
       "0  2025-05-31T13:14:52.831Z  -15.8326  -174.2043  108.698  4.7      mb   62   \n",
       "\n",
       "   gap   dmin   rms  ...                   updated  \\\n",
       "0   93  3.023  0.88  ...  2025-05-31T13:34:35.040Z   \n",
       "\n",
       "                        place        type horizontalError depthError  \\\n",
       "0  45 km WNW of Hihifo, Tonga  earthquake           11.78      7.257   \n",
       "\n",
       "   magError  magNst    status  locationSource magSource  \n",
       "0     0.055     101  reviewed              us        us  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGgcXCzyNQtN"
   },
   "source": [
    "#### Importing HTML Files from the Web\n",
    "\n",
    "Working with unstructured HTML files relies heavily on library functions. This one, however, is well-structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "F4oVabZ6NQtO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                City      Country Code\n",
       " 0            Aalborg      Denmark  AAL\n",
       " 1           Aalesund       Norway  AES\n",
       " 2             Aarhus      Denmark  AAR\n",
       " 3     Abbotsford, BC       Canada  YXX\n",
       " 4           Aberdeen     Scotland  ABZ\n",
       " ...              ...          ...  ...\n",
       " 1573        Zanzibar     Tanzania  ZNZ\n",
       " 1574        Zaragoza        Spain  ZAZ\n",
       " 1575       Zhengzhou        China  CGO\n",
       " 1576        Zhoushan        China  HSN\n",
       " 1577          Zurich  Switzerland  ZRH\n",
       " \n",
       " [1578 rows x 3 columns]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.ccra.com/airport-codes/'\n",
    "\n",
    "df = pd.read_html(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PiPCjFc7-281"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aalesund</td>\n",
       "      <td>Norway</td>\n",
       "      <td>AES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>AAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford, BC</td>\n",
       "      <td>Canada</td>\n",
       "      <td>YXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>ABZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>Zanzibar</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>ZNZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>Zaragoza</td>\n",
       "      <td>Spain</td>\n",
       "      <td>ZAZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>Zhengzhou</td>\n",
       "      <td>China</td>\n",
       "      <td>CGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>Zhoushan</td>\n",
       "      <td>China</td>\n",
       "      <td>HSN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>Zurich</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>ZRH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1578 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City      Country Code\n",
       "0            Aalborg      Denmark  AAL\n",
       "1           Aalesund       Norway  AES\n",
       "2             Aarhus      Denmark  AAR\n",
       "3     Abbotsford, BC       Canada  YXX\n",
       "4           Aberdeen     Scotland  ABZ\n",
       "...              ...          ...  ...\n",
       "1573        Zanzibar     Tanzania  ZNZ\n",
       "1574        Zaragoza        Spain  ZAZ\n",
       "1575       Zhengzhou        China  CGO\n",
       "1576        Zhoushan        China  HSN\n",
       "1577          Zurich  Switzerland  ZRH\n",
       "\n",
       "[1578 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaWhHAk9NQtQ"
   },
   "source": [
    "#### Importing XML Files from the Web\n",
    "\n",
    "XML files are semi-structured, but you're at the mercy of the file creator. If every record has the same format it will be much easier, but practical applications often require a lot of custom code. Here are a few examples: https://pandas.pydata.org/docs/user_guide/io.html#io-read-xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppLnAmKVNQtQ"
   },
   "source": [
    "#### Importing JSON Files from the Web\n",
    "\n",
    "Like XML, JSON files are semi-structured and may require work to capture the schema into a dataframe. Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8VB9EoRrNQtS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>language</th>\n",
       "      <th>id</th>\n",
       "      <th>bio</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adeel Solangi</td>\n",
       "      <td>Sindhi</td>\n",
       "      <td>V59OF92YF627HFY0</td>\n",
       "      <td>Donec lobortis eleifend condimentum. Cras dict...</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afzal Ghaffar</td>\n",
       "      <td>Sindhi</td>\n",
       "      <td>ENTOCR13RSCLZ6KU</td>\n",
       "      <td>Aliquam sollicitudin ante ligula, eget malesua...</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aamir Solangi</td>\n",
       "      <td>Sindhi</td>\n",
       "      <td>IAKPO3R4761JDRVG</td>\n",
       "      <td>Vestibulum pharetra libero et velit gravida eu...</td>\n",
       "      <td>7.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abla Dilmurat</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>5ZVOEPMJUI4MB4EN</td>\n",
       "      <td>Donec lobortis eleifend condimentum. Morbi ac ...</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adil Eli</td>\n",
       "      <td>Uyghur</td>\n",
       "      <td>6VTI8X6LL0MMPJCC</td>\n",
       "      <td>Vivamus id faucibus velit, id posuere leo. Mor...</td>\n",
       "      <td>6.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name language                id  \\\n",
       "0  Adeel Solangi   Sindhi  V59OF92YF627HFY0   \n",
       "1  Afzal Ghaffar   Sindhi  ENTOCR13RSCLZ6KU   \n",
       "2  Aamir Solangi   Sindhi  IAKPO3R4761JDRVG   \n",
       "3  Abla Dilmurat   Uyghur  5ZVOEPMJUI4MB4EN   \n",
       "4       Adil Eli   Uyghur  6VTI8X6LL0MMPJCC   \n",
       "\n",
       "                                                 bio  version  \n",
       "0  Donec lobortis eleifend condimentum. Cras dict...     6.10  \n",
       "1  Aliquam sollicitudin ante ligula, eget malesua...     1.88  \n",
       "2  Vestibulum pharetra libero et velit gravida eu...     7.27  \n",
       "3  Donec lobortis eleifend condimentum. Morbi ac ...     2.53  \n",
       "4  Vivamus id faucibus velit, id posuere leo. Mor...     6.49  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://microsoftedge.github.io/Demos/json-dummy-data/64KB.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient = 'columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGdFWr-Py1aH"
   },
   "source": [
    "Handy reference on JSON: https://www.dataquest.io/blog/python-json-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIArBrFFNQtV"
   },
   "source": [
    "## Part 2: Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aFUJrhENQtW"
   },
   "source": [
    "Data munging is manipulating data to get it into a form that we can start running analyses on (which usually means getting the data into a DataFrame). Before we get to this stage, we may need to remove headers or footers, transpose columns to rows, split wide data tables into long ones, and so on. (Nb. Excel files can be particularly troublesome, because users can format their data in mixed, complex shapes.) Essentially, we need to follow Hadley Wickham's guidelines for tidy datasets (http://vita.had.co.nz/papers/tidy-data.html):\n",
    "\n",
    "The end goal of the cleaning data process:\n",
    "\n",
    "- each variable should be in one column\n",
    "- each observation should comprise one row\n",
    "- each type of observational unit should form one table\n",
    "- include key columns for linking multiple tables\n",
    "- the top row contains (sensible) variable names\n",
    "- in general, save data as one file per table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kmjox61xNQtW"
   },
   "source": [
    "### Dataset Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29PQdqUMNQtX"
   },
   "source": [
    "Once we have our dataset in a DataFrame (or Series, if our data is only 1-dimensional), we can start examining its size and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04lspVeiNQtY"
   },
   "source": [
    "How many rows and columns are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DkO6SxSmNQtY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check the rows and columns of the dataset\n",
    "bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "camJWA-DNQta"
   },
   "source": [
    "What are the column names in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jDzIHgjXNQtb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
       "       'casual', 'registered', 'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check the column names in dataset\n",
    "bikes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL7Cm_4NNQtc"
   },
   "source": [
    "What are the data types of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LtKQtrdSNQtd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant         int64\n",
       "dteday         object\n",
       "season          int64\n",
       "yr              int64\n",
       "mnth            int64\n",
       "hr              int64\n",
       "holiday         int64\n",
       "weekday         int64\n",
       "workingday      int64\n",
       "weathersit      int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "hum           float64\n",
       "windspeed     float64\n",
       "casual          int64\n",
       "registered      int64\n",
       "cnt             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check the data types in the for all the columns\n",
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "p7WciAwrNQtf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
      "0            1  2011-01-01       1   0     1   0        0        6   \n",
      "1            2  2011-01-01       1   0     1   1        0        6   \n",
      "2            3  2011-01-01       1   0     1   2        0        6   \n",
      "3            4  2011-01-01       1   0     1   3        0        6   \n",
      "4            5  2011-01-01       1   0     1   4        0        6   \n",
      "...        ...         ...     ...  ..   ...  ..      ...      ...   \n",
      "17374    17375  2012-12-31       1   1    12  19        0        1   \n",
      "17375    17376  2012-12-31       1   1    12  20        0        1   \n",
      "17376    17377  2012-12-31       1   1    12  21        0        1   \n",
      "17377    17378  2012-12-31       1   1    12  22        0        1   \n",
      "17378    17379  2012-12-31       1   1    12  23        0        1   \n",
      "\n",
      "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
      "0               0           1  0.24  0.2879  0.81     0.0000       3   \n",
      "1               0           1  0.22  0.2727  0.80     0.0000       8   \n",
      "2               0           1  0.22  0.2727  0.80     0.0000       5   \n",
      "3               0           1  0.24  0.2879  0.75     0.0000       3   \n",
      "4               0           1  0.24  0.2879  0.75     0.0000       0   \n",
      "...           ...         ...   ...     ...   ...        ...     ...   \n",
      "17374           1           2  0.26  0.2576  0.60     0.1642      11   \n",
      "17375           1           2  0.26  0.2576  0.60     0.1642       8   \n",
      "17376           1           1  0.26  0.2576  0.60     0.1642       7   \n",
      "17377           1           1  0.26  0.2727  0.56     0.1343      13   \n",
      "17378           1           1  0.26  0.2727  0.65     0.1343      12   \n",
      "\n",
      "       registered  cnt  \n",
      "0              13   16  \n",
      "1              32   40  \n",
      "2              27   32  \n",
      "3              10   13  \n",
      "4               1    1  \n",
      "...           ...  ...  \n",
      "17374         108  119  \n",
      "17375          81   89  \n",
      "17376          83   90  \n",
      "17377          48   61  \n",
      "17378          37   49  \n",
      "\n",
      "[17379 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check the row index of the dataset\n",
    "#Convert the dataset to dataframe\n",
    "bikes_df = pd.DataFrame(bikes)\n",
    "print(bikes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqHDi7_GNQtf"
   },
   "source": [
    "What is the (row) index for this DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=17379, step=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtxBEejpNQti"
   },
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tzns_pFsNQtj"
   },
   "source": [
    "Slicing refers to extracting part of a Python object such as a list or dataframe.\n",
    "\n",
    "It is often preferable to refer to DataFrame columns by name, but there is more than one way to do this.\n",
    "Do `bikes['season']` and `bikes[['season']]` give the same object? Demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "gSlC2oZXNQtj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "17374    1\n",
      "17375    1\n",
      "17376    1\n",
      "17377    1\n",
      "17378    1\n",
      "Name: season, Length: 17379, dtype: int64\n",
      "       season\n",
      "0           1\n",
      "1           1\n",
      "2           1\n",
      "3           1\n",
      "4           1\n",
      "...       ...\n",
      "17374       1\n",
      "17375       1\n",
      "17376       1\n",
      "17377       1\n",
      "17378       1\n",
      "\n",
      "[17379 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check both bikes_df['season'] and bikes_df[['season']] are the same. Answer: Yes\n",
    "print(bikes_df['season'])\n",
    "print(bikes_df[['season']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsCATb2iNQtl"
   },
   "source": [
    "How would we use object notation to show the first 4 rows of `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "T5D_UU5KNQtm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.2879\n",
      "1    0.2727\n",
      "2    0.2727\n",
      "3    0.2879\n",
      "Name: atemp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "# Show the first 4 rows of column atemp by using object notation\n",
    "print(bikes_df.atemp[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWKI9FNDNQto"
   },
   "source": [
    "Algorithms that loop over multiple columns often access DataFrame columns by index. However, none of the following work (try them out by uncommenting / removing the \"#E: \" ):\n",
    "\n",
    "!!! Pandas now highly recommends the use of explicit index calling via either .loc or .iloc. Below are examples of implicit index calling which is being deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "NgWFEEmWNQto"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([0], dtype='int32')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bikes_df[[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m      2\u001b[0m bikes_df[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m bikes_df[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([0], dtype='int32')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "bikes_df[[0]]\n",
    "bikes_df[0]\n",
    "bikes_df[0,0]\n",
    "bikes_df[[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeUJ7D5qNQtq"
   },
   "source": [
    "What is the correct way to access the 1st row of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "d4Kidzz0NQtq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Access first row of the dataframe by index\n",
    "bikes_df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZa1v-2jNQts"
   },
   "source": [
    "What is the correct way to access the 2nd column of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "T4GmE0EsNQtt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-01-01\n",
       "1        2011-01-01\n",
       "2        2011-01-01\n",
       "3        2011-01-01\n",
       "4        2011-01-01\n",
       "            ...    \n",
       "17374    2012-12-31\n",
       "17375    2012-12-31\n",
       "17376    2012-12-31\n",
       "17377    2012-12-31\n",
       "17378    2012-12-31\n",
       "Name: dteday, Length: 17379, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Access second column of the dataframe by index\n",
    "bikes_df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSvqNbVUNQtu"
   },
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRPFEN1HNQtu"
   },
   "source": [
    "What is the Pandas `isnull` function for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xyw5qkWWNQtu"
   },
   "source": [
    "?\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iby8s2VSNQtv"
   },
   "source": [
    "We can apply `isnull` to the `bikes` DataFrame to show the result for every element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "YRQY-1ViNQtv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  dteday  season     yr   mnth     hr  holiday  weekday  workingday  \\\n",
       "0    False   False   False  False  False  False    False    False       False   \n",
       "1    False   False   False  False  False  False    False    False       False   \n",
       "2    False   False   False  False  False  False    False    False       False   \n",
       "3    False   False   False  False  False  False    False    False       False   \n",
       "4    False   False   False  False  False  False    False    False       False   \n",
       "\n",
       "   weathersit   temp  atemp    hum  windspeed  casual  registered    cnt  \n",
       "0       False  False  False  False      False   False       False  False  \n",
       "1       False  False  False  False      False   False       False  False  \n",
       "2       False  False  False  False      False   False       False  False  \n",
       "3       False  False  False  False      False   False       False  False  \n",
       "4       False  False  False  False      False   False       False  False  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IyZaICINQtw"
   },
   "source": [
    "However, we usually start at a higher level. How many nulls are in `bikes` altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "SbDfiSqVNQtx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "hr            0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Calculate the total missing value in respective columns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "bikes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10jWUf4VNQty"
   },
   "source": [
    "If this result were nonzero we would next want to find out which columns contained nulls. How can this be done in one line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "qBv3l_s2NQtz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       False\n",
       "dteday        False\n",
       "season        False\n",
       "yr            False\n",
       "mnth          False\n",
       "hr            False\n",
       "holiday       False\n",
       "weekday       False\n",
       "workingday    False\n",
       "weathersit    False\n",
       "temp          False\n",
       "atemp         False\n",
       "hum           False\n",
       "windspeed     False\n",
       "casual        False\n",
       "registered    False\n",
       "cnt           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Find the column that contains NULL\n",
    "bikes_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1MsvXf7NQt0"
   },
   "source": [
    "What is the Numpy object `nan` used for? (Write a descriptive answer.)\n",
    "Numpy 'nan' use for handling missing or undefined numeric data. Its properties as floating point value and unique comparison behavior. It provides a standardized and computationally efficient way to mark and manage gaps in data that would otherwise lead to errors or inaccurate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaeGVh6ZNQt0"
   },
   "source": [
    "?\n",
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9bFlPsrNQt1"
   },
   "source": [
    "Write (and verify) a function that performs scalar division with built-in handling of the edge cases (i.e. divide by zero, divide by NaN). Return a value for the edge cases instead of just trapping the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "-Cq2VAb8NQt1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "def divide (x, y): \n",
    "    if y == 0:\n",
    "        quotient = np.nan\n",
    "    else: \n",
    "        quotient = x/y\n",
    "    return quotient\n",
    "print(divide(100,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7Up8D6lNQt2"
   },
   "source": [
    "Apply the Pandas `isna` function to the following data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "l_YvVav3NQt3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3 nan\n"
     ]
    }
   ],
   "source": [
    "x = 2.3\n",
    "y = np.nan\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "QAcf1FU1NQt4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is NA ?: False\n",
      "y is NA ?: True\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check x and y whether NA\n",
    "print(f\"x is NA ?: {pd.isna(x)}\")\n",
    "print(f\"y is NA ?: {pd.isna(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "qJUM31pANQt5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan  3.]\n",
      " [ 4.  5. nan]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "4LBgqnubNQt6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array got NA ?:\n",
      " [[False  True False]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check the array whether there is NA\n",
    "print(f\"Array got NA ?:\\n {pd.isna(array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhFaZbzQNQt7"
   },
   "source": [
    "How is the pandas I/O parameter `na_values` used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mw-PvrTeNQt8"
   },
   "source": [
    "? ANSWER: \n",
    "In Python, specifically within the pandas library, na_values is a parameter used in functions like read_csv() to specify additional strings that should be recognized as missing or \"Not Available\" (NA) values, in addition to the default set of strings. When na_values is used, the specified strings are converted to NaN (Not a Number), a special floating-point value used by pandas to represent missing numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOW3ICgwNQt8"
   },
   "source": [
    "### Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZhJ9-XrNQt8"
   },
   "source": [
    "#### Counts\n",
    "\n",
    "When there are categorical variables in a dataset we will want to know how many possible values there are in each column. (Nb. If the dataset is a sample of a larger one, our sample may not capture all possible values of every categorical.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RitKNRPCNQt8"
   },
   "source": [
    "How many (different) seasons are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "eqmE4OMsNQt9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season\n",
       "3    4496\n",
       "2    4409\n",
       "1    4242\n",
       "4    4232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Check how many different seasons in bikes dataset\n",
    "bikes_df['season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peDZrNJjNQt-"
   },
   "source": [
    "#### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIKyD5LHNQt-"
   },
   "source": [
    "Print the range (min and max) of the `instant`, `dteday`, and `windspeed` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "mVAOjyocNQt-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min of the columns: \n",
      " instant               1\n",
      "dteday       2011-01-01\n",
      "windspeed           0.0\n",
      "dtype: object\n",
      "max of the columns: \n",
      " instant           17379\n",
      "dteday       2012-12-31\n",
      "windspeed        0.8507\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Print the range of the columns 'instant', 'dteday', 'windspeed'\n",
    "range_min= bikes_df[[\"instant\", \"dteday\", \"windspeed\"]].min()\n",
    "range_max= bikes_df[[\"instant\", \"dteday\", \"windspeed\"]].max()\n",
    "print(f\"min of the columns: \\n {range_min}\")\n",
    "print(f\"max of the columns: \\n {range_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5oDTJHoNQt_"
   },
   "source": [
    "The following computes and prints the overall minimum and maximum of the numeric data columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "yiIKiPT4NQuA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 17379.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_min, bikes_max = (min(bikes.min(numeric_only=True)), max(bikes.max(numeric_only=True)))\n",
    "bikes_min, bikes_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyKKjxJoNQuB"
   },
   "source": [
    "#### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hxPA3sXNQuB"
   },
   "source": [
    "Pandas makes computing quantiles easy. This is how to get the median of a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "n1GLqWOoNQuB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4848"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['atemp'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBWCtrCrNQuD"
   },
   "source": [
    "Of course, the `quantiles` method can take a tuple as its argument. Compute the 10th, 25th, 50th, 75th, and 90th percentiles in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "iu8bzEktNQuD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10    0.2424\n",
       "0.25    0.3333\n",
       "0.50    0.4848\n",
       "0.75    0.6212\n",
       "0.90    0.6970\n",
       "Name: atemp, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "# Compute the 10th, 25th, 50th, 75th, and 90th percentiles\n",
    "bikes['atemp'].quantile([0.1, 0.25, 0.50, 0.75, 0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJnCB_bqNQuF"
   },
   "source": [
    "#### Cuts\n",
    "\n",
    "Sometimes we want to split the sample not by the quantiles of the distribution but by the range of the data. Let's take a closer look at `atemp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "vn_cvvY-NQuF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bikes['atemp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "ae7zUQp-NQuH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8965</th>\n",
       "      <td>8966</td>\n",
       "      <td>2012-01-14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12406</th>\n",
       "      <td>12407</td>\n",
       "      <td>2012-06-06</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>1061</td>\n",
       "      <td>2011-02-16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>3602</td>\n",
       "      <td>2011-06-03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>30</td>\n",
       "      <td>141</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>3873</td>\n",
       "      <td>2011-06-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.2537</td>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "8965      8966  2012-01-14       1   1     1  10        0        6   \n",
       "12406    12407  2012-06-06       2   1     6   3        0        3   \n",
       "1060      1061  2011-02-16       1   0     2  22        0        3   \n",
       "3601      3602  2011-06-03       2   0     6  23        0        5   \n",
       "3872      3873  2011-06-15       2   0     6   6        0        3   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "8965            0           1  0.16  0.2273  0.47     0.0000      14   \n",
       "12406           1           1  0.46  0.4545  0.82     0.0000       0   \n",
       "1060            1           1  0.34  0.3333  0.53     0.1940      12   \n",
       "3601            1           1  0.58  0.5455  0.46     0.1045      30   \n",
       "3872            1           1  0.50  0.4848  0.63     0.2537      11   \n",
       "\n",
       "       registered  cnt  \n",
       "8965          135  149  \n",
       "12406           8    8  \n",
       "1060           61   73  \n",
       "3601          141  171  \n",
       "3872          110  121  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thwFHrthNQuJ"
   },
   "source": [
    "Suppose we decide to sort these values into 4 bins of equal width, but we want to apply the resulting groups to the entire DataFrame. Basically, we need to add a row label that indicates which bin each sample belongs in. Let's call this label \"atemp_level\", and use the `cut` method to populate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "z7mXBeXMNQuJ"
   },
   "outputs": [],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vf3Q5vbQNQuL"
   },
   "source": [
    "What is the type of `atemp_level`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "dhlx1W-VNQuL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "type(atemp_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuDXdgfxNQuN"
   },
   "source": [
    "Here is a random sample of `atemp_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "4Qure0UbNQuN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10293    (0.25, 0.5]\n",
       "8798     (0.25, 0.5]\n",
       "12255    (0.5, 0.75]\n",
       "3047     (0.5, 0.75]\n",
       "13054    (0.5, 0.75]\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, interval[float64, right]): [(-0.001, 0.25] < (0.25, 0.5] < (0.5, 0.75] < (0.75, 1.0]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q59qWmqfNQuO"
   },
   "source": [
    "So, by default, `cut` produces labels that indicate the bin boundaries for each element in the series it was applied to. Usually, we will specify labels that are appropriate to the discretisation we are applying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "VYsD8ZwDNQuP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11852    warm\n",
       "13386    warm\n",
       "6196     warm\n",
       "13668     hot\n",
       "6751     warm\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, object): ['cool' < 'mild' < 'warm' < 'hot']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "atemp_level.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD-3g9qLNQuQ"
   },
   "source": [
    "Incorporate the new `atemp_level` column into the `bikes` DataFrame and use it to count the number of \"mild\" `atemp` entries in `season` 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "O5fRRbXwNQuR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count the numnber: \n",
      " 1829\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "#Combine the column 'atemp_level' into the dataframe\n",
    "bikes['atemp_level'] = pd.cut(bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "#Count the number of \"mild\" atemp and season == 2\n",
    "count = len(bikes[(bikes['atemp_level']==\"mild\") & (bikes['season'] == 2)])\n",
    "print(f\"count the numnber: \\n {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZN-0yDQNQuR"
   },
   "source": [
    "*Nb. The `atemp_level` variable we created is what the R language calls a \"factor\". Pandas has introduced a new data type called \"category\" that is similar to R's factors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2asO3_lDFm8"
   },
   "source": [
    ">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlasiTKgDGdA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2025 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
